{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unknown_face_classification_article.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lkOQWdX4Na",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLNBgWrAk1J-",
        "colab_type": "text"
      },
      "source": [
        "# Unknown face recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoxzlLydbjOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Necessary files for training and inference of model\n",
        "\n",
        "!cp ./drive/My\\ Drive/Mini_casia.zip .\n",
        "!cp ./drive/My\\ Drive/facenet_keras.h5 .\n",
        "!cp ./drive/My\\ Drive/tarantino.mp4 .\n",
        "!unzip ./Mini_casia"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEztZsX5C8AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installation of MTCNN and EVM\n",
        "\n",
        "!pip install mtcnn\n",
        "#!unzip VGG200.zip\n",
        "!pip install EVM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWpu0V80JB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d0e6fd5-0026-468d-b15d-9d75b62686f1"
      },
      "source": [
        "%%writefile detect_face_video.py\n",
        "\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import os\n",
        "from numpy import savez_compressed\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class detect_face:\n",
        "    def __init__(self):\n",
        "        self.detect = MTCNN()\n",
        "        self.img = None\n",
        "        self.res = None \n",
        "        \n",
        "\n",
        "    \n",
        "    def vid_detect_face(self,frame):\n",
        "        self.img_v = frame\n",
        "        self.res_v = self.detect.detect_faces(frame)\n",
        "        return(self.res_v)         \n",
        "    \n",
        "    def vid_crop_resize(self):\n",
        "      self.face = []\n",
        "      for i in range(len(self.res_v)):\n",
        "          if self.res_v[i]['confidence']>=0.90:\n",
        "            x1=self.res_v[i]['box'][0]\n",
        "            y1=self.res_v[i]['box'][1]\n",
        "            x2=self.res_v[i]['box'][0]+self.res_v[i]['box'][2]\n",
        "            y2=self.res_v[i]['box'][1]+self.res_v[i]['box'][3]\n",
        "            self._face = self.img_v[y1:y2,x1:x2]\n",
        "            self._face = cv2.resize(self._face,(160,160),cv2.INTER_AREA)\n",
        "            self.face.append(self._face)\n",
        "      return(self.face)   \n",
        "    \n",
        "    def load_facenet(self):\n",
        "        self.model = load_model('facenet_keras.h5')\n",
        "        print('Facenet model loaded')  \n",
        "    \n",
        "    def get_embedding(self, face_pixels):\n",
        "\n",
        "        face_pixels = face_pixels.astype('float32')\n",
        "        mean, std = face_pixels.mean(), face_pixels.std()\n",
        "        face_pixels = (face_pixels - mean) / std\n",
        "        samples = expand_dims(face_pixels, axis=0)\n",
        "        yhat = self.model.predict(samples)\n",
        "        return yhat[0]\n",
        "    \n",
        "    def normalize(self,data):\n",
        "        in_encoder = Normalizer(norm='l2')\n",
        "        data = in_encoder.transform(data)\n",
        "        return(data)\n",
        "\n",
        "    def draw_detect(self,img):\n",
        "    \n",
        "     l=25\n",
        "     t=2\n",
        "     for i in range(len(self.res_v)):\n",
        "        x1 = self.res_v[i]['box'][0]\n",
        "        y1 = self.res_v[i]['box'][1]\n",
        "        x2 = self.res_v[i]['box'][0] + self.res_v[i]['box'][2]\n",
        "        y2 = self.res_v[i]['box'][1] + self.res_v[i]['box'][3]\n",
        "        \n",
        "        cv2.line(img,(x1,y1),(x1+l,y1),(255,0,0),t)\n",
        "        cv2.line(img,(x1,y1),(x1,y1+l),(255,0,0),t)\n",
        "        \n",
        "        cv2.line(img,(x2,y1),(x2-l,y1),(255,0,0),t)\n",
        "        cv2.line(img,(x2,y1),(x2,y1+l),(255,0,0),t)\n",
        "        \n",
        "        cv2.line(img,(x2,y2),(x2-l,y2),(255,0,0),t)\n",
        "        cv2.line(img,(x2,y2),(x2,y2-l),(255,0,0),t)\n",
        "       \n",
        "        cv2.line(img,(x1,y2),(x1+l,y2),(255,0,0),t)\n",
        "        cv2.line(img,(x1,y2),(x1,y2-l),(255,0,0),t)\n",
        "\n",
        "        #cv2.line(img,(x1[i]+int(l/2),y1[i]+int(b/outer_len)),(x1[i]+int(l/2),y1[i]-int(b/inner_len)),(0,255,255),6)\n",
        "        #cv2.line(img,(x1[i]+int(l/outer_len),y1[i]+int(b/2)),(x1[i]-int(l/inner_len),y1[i]+int(b/2)),(0,255,255),6)\n",
        "        #cv2.line(img,(x1[i]+int(l/2),y1[i]+b-int(b/outer_len)),(x1[i]+int(l/2),y1[i]+b+int(b/inner_len)),(0,255,255),6)\n",
        "        #cv2.line(img,(x1[i]+int(l)-int(l/outer_len),y1[i]+int(b/2)),(x1[i]+l+int(l/inner_len),y1[i]+int(b/2)),(0,255,255),6)\n",
        "        \n",
        "    \n",
        "     return(img)\n",
        "        \n",
        "        \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing detect_face_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auxr6BwGxZBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96d90918-015b-4feb-b920-a8caefd8c9ce"
      },
      "source": [
        "%%writefile extract_embeds.py\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "# Train and test folder created are used in this file. The faces are detected using MTCNN\n",
        "# then these faces are extracted and passed to facenet model to return the embeddings of these faces\n",
        "#Make sure to load the .h5 facenet file, before running this\n",
        "#----------------------------------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from numpy import savez_compressed\n",
        "from numpy import load \n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import argparse\n",
        "\n",
        "beginn = time.time()\n",
        "\n",
        "class extract_embeds:\n",
        "    def __init__(self,path):\n",
        "        self.detect = MTCNN()\n",
        "        self.root_path = path\n",
        "        self.X_train_faces = []\n",
        "        self.y_train_faces = []\n",
        "        self.X_test_faces = []\n",
        "        self.y_test_faces = []\n",
        "        self.newTrainX = []\n",
        "        self.newTestX = []\n",
        "\n",
        "    def identify_face(self,path):\n",
        "        self.img = cv2.imread(path)\n",
        "        self.img = cv2.cvtColor(self.img,cv2.COLOR_BGR2RGB)\n",
        "        self.res = self.detect.detect_faces(self.img)\n",
        "        return(self.res)\n",
        "    \n",
        "    def crop_resize(self):\n",
        "        x1=self.res[0]['box'][0]\n",
        "        y1=self.res[0]['box'][1]\n",
        "        x2=self.res[0]['box'][0]+self.res[0]['box'][2]\n",
        "        y2=self.res[0]['box'][1]+self.res[0]['box'][3]\n",
        "        self.face = self.img[y1:y2,x1:x2]\n",
        "        np.shape(self.face)\n",
        "        self.face = cv2.resize(self.face,(160,160),cv2.INTER_AREA)\n",
        "        return(self.face)\n",
        "        \n",
        "    def check_folders(self):\n",
        "        if 'outputs' not in os.listdir():\n",
        "            os.makedirs('./outputs')\n",
        "\n",
        "        y,x = sorted(os.listdir(self.root_path),key=len)\n",
        "        assert(x == 'train' or x == 'Train' or x == 'TRAIN')\n",
        "        assert(y == 'test' or y == 'Test' or y == 'TEST')\n",
        "        self.train_path = self.root_path+'/'+x\n",
        "        self.test_path = self.root_path+'/'+y\n",
        "        train_classes = os.listdir(self.train_path)\n",
        "        test_classes = os.listdir(self.test_path)\n",
        "        try:\n",
        "            assert(len(train_classes) == len(test_classes))\n",
        "            print('No. of train classes: {}'.format(len(train_classes)))\n",
        "            print('No. of test classes: {}'.format(len(test_classes)))\n",
        "        except Exception as e:\n",
        "            print('Error: Number of classes in train and test should be same')\n",
        "    \n",
        "    def extract_faces(self):\n",
        "        start1 = time.time()\n",
        "        print('Inside train folder ....')\n",
        "        for label in os.listdir(self.train_path): \n",
        "            print('Images of '+label + ' under process')\n",
        "            for pics in os.listdir(self.train_path+'/'+label):\n",
        "              if pics.endswith('.jpg'):    \n",
        "                #print('Name of the pic:',pics)\n",
        "                try:\n",
        "                  face_details = self.identify_face(self.train_path+'/'+label+'/'+pics)\n",
        "                  out = self.crop_resize()\n",
        "                  self.X_train_faces.append(out)\n",
        "                  self.y_train_faces.append(label)\n",
        "                except:\n",
        "                  print('Pic {} in {} is not processed'.format(pics,label))\n",
        "                  continue\n",
        "        print('time taken to process {} secs'.format(time.time()-start1))\n",
        "    \n",
        "        start2 = time.time()\n",
        "        print('Inside test folder ....')\n",
        "        for label in os.listdir(self.test_path):\n",
        "            \n",
        "            print('Images of '+label + ' under process')\n",
        "            for pics in os.listdir(self.test_path+'/'+label):\n",
        "              if pics.endswith('.jpg') or pics.endswith('.jpeg') or pics.endswith('.png') or pics.endswith('.tif'):\n",
        "                #print('Name of the pic:',pics)\n",
        "                try:\n",
        "                  face_details = self.identify_face(self.test_path+'/'+label+'/'+pics)\n",
        "                  out = self.crop_resize()\n",
        "                  self.X_test_faces.append(out)\n",
        "                  self.y_test_faces.append(label)\n",
        "                except:\n",
        "                  print('Pic {} in {} is not processed'.format(pics,label))\n",
        "                  continue\n",
        "        print('time taken to process {} secs'.format(time.time()-start2))\n",
        "        savez_compressed('./outputs/Extracted_faces.npz', self.X_train_faces, self.y_train_faces, self.X_test_faces, self.y_test_faces)\n",
        "        return(self.X_train_faces, self.y_train_faces, self.X_test_faces, self.y_test_faces)\n",
        "\n",
        "    def load_facenet(self):\n",
        "        self.model = load_model('facenet_keras.h5')\n",
        "        print('Facenet model loaded')  \n",
        "    \n",
        "    def get_embedding(self, face_pixels):\n",
        "\n",
        "        face_pixels = face_pixels.astype('float32')\n",
        "        mean, std = face_pixels.mean(), face_pixels.std()\n",
        "        face_pixels = (face_pixels - mean) / std\n",
        "        samples = expand_dims(face_pixels, axis=0)\n",
        "        yhat = self.model.predict(samples)\n",
        "        return(self.normalize([yhat[0]]))\n",
        "    \n",
        "    def normalize(self,data):\n",
        "        in_encoder = Normalizer(norm='l2')\n",
        "        data = in_encoder.transform(data)\n",
        "        return(data)\n",
        "\n",
        "    def extract_embeddings(self):\n",
        "        # convert each face in the train set to an embedding\n",
        "        for face_pixels in self.X_train_faces:\n",
        "            embedding = self.get_embedding(face_pixels)\n",
        "            self.newTrainX.append(embedding)\n",
        "        self.newTrainX = asarray(self.newTrainX)\n",
        "        print(self.newTrainX.shape)\n",
        "\n",
        "        # convert each face in the test set to an embedding \n",
        "        for face_pixels in self.X_test_faces:\n",
        "            embedding = self.get_embedding(face_pixels)\n",
        "            self.newTestX.append(embedding)\n",
        "        self.newTestX = asarray(self.newTestX)\n",
        "        print(self.newTestX.shape)                                      \n",
        "        # save arrays to one file in compressed format\n",
        "        savez_compressed('./outputs/Extracted_embeddings.npz', self.newTrainX, self.y_train_faces, self.newTestX, self.y_test_faces)\n",
        "        print('Time taken from reading images to extracting embeds: {} s'.format(time.time()-beginn))\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "     \n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--input_path',default=None, required = True, \n",
        "                        help = 'Enter the path of the folder contains train and test images')\n",
        "    args=parser.parse_args()\n",
        "    \n",
        "    _extract_embeds = extract_embeds(args.input_path)\n",
        "    _extract_embeds.check_folders()\n",
        "    x,y,a,b = _extract_embeds.extract_faces()\n",
        "    _extract_embeds.load_facenet()\n",
        "    _extract_embeds.extract_embeddings()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing extract_embeds.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knJfsNlQx1yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7be1fe22-e180-41ec-a1f9-62626fe2003e"
      },
      "source": [
        "\n",
        "!python extract_embeds.py --input_path ./Mini_casia\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-17 19:08:37.595550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:08:39.549902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-17 19:08:39.609434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:39.610194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 19:08:39.610262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:08:39.842224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 19:08:39.970238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 19:08:39.989715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 19:08:40.256841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 19:08:40.277380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 19:08:40.788294: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:08:40.788527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.789318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.789889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 19:08:40.803145: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-08-17 19:08:40.803394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ce0bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 19:08:40.803427: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-17 19:08:40.995816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.996528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ce0d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 19:08:40.996559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-17 19:08:40.997491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.998127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 19:08:40.998192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:08:40.998252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 19:08:40.998279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 19:08:40.998308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 19:08:40.998332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 19:08:40.998356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 19:08:40.998379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:08:40.998470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.999132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:40.999682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 19:08:41.001835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:08:44.807382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-17 19:08:44.807449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-17 19:08:44.807462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-17 19:08:44.813417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:44.814188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:08:44.814780: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-17 19:08:44.814829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "No. of train classes: 4\n",
            "No. of test classes: 4\n",
            "Inside train folder ....\n",
            "Images of tarantino under process\n",
            "2020-08-17 19:08:45.482713: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:08:50.556722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07c63e0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Images of Hank under process\n",
            "Images of milla under process\n",
            "Images of neve under process\n",
            "time taken to process 421.27644515037537 secs\n",
            "Inside test folder ....\n",
            "Images of tarantino under process\n",
            "Images of Hank under process\n",
            "Images of milla under process\n",
            "Images of neve under process\n",
            "time taken to process 15.803902387619019 secs\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Facenet model loaded\n",
            "(1148, 1, 128)\n",
            "(44, 1, 128)\n",
            "Time taken from reading images to extracting embeds: 515.6178805828094 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_a-fkFwJPss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f443869-8615-4079-c264-a500dc0bf7cc"
      },
      "source": [
        "%%writefile train_evm.py\n",
        "\n",
        "\n",
        "##------------------------------------------------------------------------------------------------------\n",
        "# In this code, we are trying to Fit EVM and check the accuracy of fitting all classes\n",
        "# Any number of classes can be used. It generates, fits each class with label and prints accuracy\n",
        "# At present this code is used to check only, the known classes\n",
        "#-------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "import EVM, scipy\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "import argparse\n",
        "import pickle\n",
        "\n",
        "\n",
        "class evm_acc:\n",
        "\n",
        "    def __init__(self,embeds_path):\n",
        "\n",
        "      self.trainX={}\n",
        "      self.testX = {}\n",
        "      self.change_test=[]\n",
        "      self.change_train=[]\n",
        "      self.predicted_cls_nam = []\n",
        "      self.embeds_path = embeds_path\n",
        "      data = load(self.embeds_path)\n",
        "      #self.tail_size = tail_size\n",
        "      self.trainx,self.trainy,self.testx,self.testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "    \n",
        "    \n",
        "    def class_split(self):\n",
        "\n",
        "        self.change_test = [i+1 for i in range(len(self.testy)-1) if (self.testy[i] != self.testy[i+1])]\n",
        "        self.change_train = [i+1 for i in range(len(self.trainy)-1) if (self.trainy[i] != self.trainy[i+1])]\n",
        "\n",
        "        for i in range(len(self.change_test)):\n",
        "          if i ==0:\n",
        "            #self.testX['class_{}'.format(i)] = self.testx[i]\n",
        "            self.testX['class_{}'.format(i)] = self.testx[i:self.change_test[i]]\n",
        "          else:\n",
        "            self.testX['class_{}'.format(i)] = self.testx[self.change_test[i-1]:self.change_test[i]]\n",
        "          #print(self.testX['class_{}'.format(i)].shape)\n",
        "        self.testX['class_{}'.format(i+1)] = self.testx[self.change_test[i]:]\n",
        "        #print(self.testX['class_3'].shape)\n",
        "\n",
        "        for i in range(len(self.change_train)):\n",
        "          #print(i)\n",
        "          if i ==0:\n",
        "            #self.trainX['class_{}'.format(i)] = self.trainx[i]\n",
        "            self.trainX['class_{}'.format(i)] = self.trainx[i:self.change_train[i]]\n",
        "          else:\n",
        "            self.trainX['class_{}'.format(i)] = self.trainx[self.change_train[i-1]:self.change_train[i]]\n",
        "          #print(self.trainX['class_{}'.format(i)].shape)\n",
        "        self.trainX['class_{}'.format(i+1)] = self.trainx[self.change_train[i]:]\n",
        "        #print(self.trainX['class_3'].shape)\n",
        "\n",
        "    def fit_evm(self,ts,dm,thresh): \n",
        "        print('Fitting the EVM Model .....')\n",
        "        self.ts = int(ts)\n",
        "        self.dm = float(dm)\n",
        "        self.thresh = float(thresh)\n",
        "        self.mevm = EVM.MultipleEVM(tailsize=self.ts, cover_threshold =self.thresh, distance_multiplier = self.dm, distance_function = scipy.spatial.distance.euclidean)\n",
        "        self.mevm.train([self.trainX[i] for i in list(self.trainX.keys())])\n",
        "\n",
        "    def extract_class(self):\n",
        "      self.indexes = np.unique(self.testy, return_index=True)[1]\n",
        "      self.uni_classes = [self.testy[index] for index in sorted(self.indexes)]\n",
        "    \n",
        "    def test_evm(self):\n",
        "        for i in range(len(self.testx)):\n",
        "          self.probs,self.index = self.mevm.max_probabilities([self.testx[i]])\n",
        "          #print(self.probs,self.index)\n",
        "          #print(self.probs,self.index,i)\n",
        "          #print('original',self.testy[i])\n",
        "          #if self.probs[0] > 0.6:\n",
        "          self.predicted_cls_nam.append(self.uni_classes[self.index[0][0]])\n",
        "            #print('class_nam',cls_nam)\n",
        "\n",
        "    def check_accuracy(self):\n",
        "\n",
        "        score = accuracy_score(self.testy,self.predicted_cls_nam) \n",
        "        print('Distance multiplier {}, cover_threshold {}, tail_size {} and Accuracy {}'.format(self.dm,self.thresh,self.ts,score))\n",
        "        #for i in range(len(testy)):\n",
        "          #print(self.testy[i],self.predicted_cls_nam[i])\n",
        "\n",
        "    def save_model(self):\n",
        "\n",
        "        with open('./outputs/EVM_model.pkl','wb') as f:\n",
        "          pickle.dump(self.mevm,f)\n",
        "\n",
        "        with open('./outputs/class_names.pkl','wb') as t:\n",
        "            pickle.dump(self.uni_classes,t)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "      parser = argparse.ArgumentParser()\n",
        "      parser.add_argument('--Embeds_path',default=None,required=True,\n",
        "                          help = \"Enter the path of the Extracted embeddings\")\n",
        "      parser.add_argument('--tail_size', default=300,\n",
        "                          help = \"Hyperparameter tail size for EVM model\")\n",
        "      parser.add_argument('--threshold', default=0.7,\n",
        "                          help = \"Hyperparameter threshold value for EVM model\")\n",
        "      parser.add_argument('--dist_multiplier', default=0.7,\n",
        "                          help = \"Hyperparameter distance multiplier for EVM model\")\n",
        "      args = parser.parse_args()\n",
        "\n",
        "\n",
        "      \n",
        "      sp = evm_acc(args.Embeds_path)\n",
        "      sp.class_split()\n",
        "      sp.fit_evm(args.tail_size,args.threshold,args.dist_multiplier)\n",
        "      sp.extract_class()\n",
        "      sp.test_evm() \n",
        "      sp.check_accuracy()\n",
        "      sp.save_model()\n",
        "      \n",
        "      \n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing train_evm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJOl_MffD8LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9caf2ed1-cb83-4abe-a3e3-9364fa235679"
      },
      "source": [
        "!python train_evm.py --Embeds_path ./outputs/Extracted_embeddings.npz"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting the EVM Model .....\n",
            "Distance multiplier 0.7, cover_threshold 0.7, tail_size 300 and Accuracy 0.9772727272727273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD4PiUZLaURg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9983650e-5379-4b2c-dddd-c6b9305bd399"
      },
      "source": [
        "%%writefile Inference_on_video.py\n",
        "\n",
        "from detect_face_video import detect_face\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "\n",
        "class inference():\n",
        "\n",
        "  def load_model(self):\n",
        "\n",
        "      with open('./outputs/EVM_model.pkl','rb') as b:\n",
        "          self.mevm = pickle.load(b)\n",
        "\n",
        "      with open('./outputs/class_names.pkl','rb') as cl:\n",
        "          self.cls_names = pickle.load(cl)\n",
        "\n",
        "  def read_video(self,path):\n",
        "\n",
        "      self.cap = cv2.VideoCapture(path)\n",
        "      width, height = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH), self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "      fourcc=cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "      #fourcc = cv2.cv.CV_FOURCC(*'XVID')\n",
        "      self.videowriter = cv2.VideoWriter('./outputs/output_video.avi', fourcc, 20, (int(width),int(height),))\n",
        "\n",
        "      #Facetection class to be loaded\n",
        "      self.df = detect_face()\n",
        "      self.df.load_facenet()\n",
        "\n",
        "  def run_inference(self):\n",
        "\n",
        "        while(self.cap.isOpened()):\n",
        "\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame0 = self.cap.read()\n",
        "            if ret == True:\n",
        "              try:\n",
        "                  frame = cv2.cvtColor(frame0,cv2.COLOR_BGR2RGB)\n",
        "                  #frame = cv2.rotate(frame1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "                  res = self.df.vid_detect_face(frame)\n",
        "                  bb_img = self.df.draw_detect(frame)\n",
        "                  face = self.df.vid_crop_resize()\n",
        "                  #print(len(res))\n",
        "                  #print(np.shape(face))\n",
        "                  for i in range(len(res)):\n",
        "                    embds = self.df.get_embedding(np.array(face[i]))\n",
        "                    print(np.shape(embds))\n",
        "                    x = self.df.normalize([embds])\n",
        "                    probs,index = self.mevm.max_probabilities(x)\n",
        "                    #bb_img = bb_img[:,:,::-1]\n",
        "                    print(probs,self.cls_names[index[0][0]]) \n",
        "                    if probs[0] > 0.9:\n",
        "                        cv2.putText(bb_img,self.cls_names[index[0][0]],(res[i]['box'][0],res[i]['box'][1]-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,0,255),2)\n",
        "                        self.videowriter.write(bb_img[:,:,::-1])\n",
        "                    if probs[0] < 0.2:\n",
        "                        cv2.putText(bb_img,\"unknown\",(res[i]['box'][0],res[i]['box'][1]-10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,0,255),2)\n",
        "                        self.videowriter.write(bb_img[:,:,::-1])\n",
        "              except Exception as e:\n",
        "                  print(e)\n",
        "                  self.videowriter.write(frame)\n",
        "                  continue\n",
        "            else:\n",
        "              break\n",
        "\n",
        "        self.videowriter.release()\n",
        "        self.cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"args.video_path\")\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--video_path',required=True,\n",
        "                          help = 'Please input the path of the input video')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    inf = inference()\n",
        "    inf.load_model()\n",
        "    \n",
        "    inf.read_video(args.video_path)\n",
        "    inf.run_inference()\n",
        "\n",
        "    \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing Inference_on_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6hN2_ZD3aAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21563b90-7467-4402-ddd1-878eaac50137"
      },
      "source": [
        "!python Inference_on_video.py --video_path ./tarantino.mp4"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-17 19:24:18.032433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "args.video_path\n",
            "2020-08-17 19:24:20.078464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-17 19:24:20.117291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.117944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 19:24:20.118011: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:24:20.119836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 19:24:20.121492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 19:24:20.121889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 19:24:20.123517: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 19:24:20.124576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 19:24:20.128129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:24:20.128293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.128935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.129526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 19:24:20.136524: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-08-17 19:24:20.136741: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f86bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 19:24:20.136774: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-17 19:24:20.247957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.248683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1f86a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-17 19:24:20.248747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-17 19:24:20.248954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.249532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-17 19:24:20.249588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:24:20.249637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-17 19:24:20.249663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-17 19:24:20.249703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-17 19:24:20.249731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-17 19:24:20.249755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-17 19:24:20.249779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:24:20.249880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.250504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.251055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-17 19:24:20.251115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-17 19:24:20.900403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-17 19:24:20.900468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-17 19:24:20.900482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-17 19:24:20.900722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.901375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-17 19:24:20.901989: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-17 19:24:20.902038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Facenet model loaded\n",
            "2020-08-17 19:24:24.727485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-17 19:24:26.522576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "(128,)\n",
            "[0.9918845257014165] tarantino\n",
            "(128,)\n",
            "[0.009162756219653234] Hank\n",
            "(128,)\n",
            "[0.014357946876212502] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.012027497601658999] Hank\n",
            "(128,)\n",
            "[0.99999978515069] tarantino\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.008779298159473647] Hank\n",
            "(128,)\n",
            "[0.9999999999999998] tarantino\n",
            "(128,)\n",
            "[0.01167183164833907] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.005276432395144415] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.03387544889825189] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.023511227578923544] Hank\n",
            "(128,)\n",
            "[0.9999999999995007] tarantino\n",
            "(128,)\n",
            "[0.01974948597412185] Hank\n",
            "(128,)\n",
            "[0.9999990321482966] tarantino\n",
            "(128,)\n",
            "[0.007900083386522483] Hank\n",
            "(128,)\n",
            "[0.015605460216890243] Hank\n",
            "(128,)\n",
            "[0.9999999615141979] tarantino\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.006032696608162524] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.04707411712762655] Hank\n",
            "(128,)\n",
            "[0.010288547675667004] Hank\n",
            "(128,)\n",
            "[1.0] tarantino\n",
            "(128,)\n",
            "[0.0062787795876410035] Hank\n",
            "(128,)\n",
            "[0.9997490397015522] tarantino\n",
            "Traceback (most recent call last):\n",
            "  File \"Inference_on_video.py\", line 82, in <module>\n",
            "    inf.run_inference()\n",
            "  File \"Inference_on_video.py\", line 41, in run_inference\n",
            "    res = self.df.vid_detect_face(frame)\n",
            "  File \"/content/detect_face_video.py\", line 33, in vid_detect_face\n",
            "    self.res_v = self.detect.detect_faces(frame)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mtcnn/mtcnn.py\", line 302, in detect_faces\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/mtcnn/mtcnn.py\", line 396, in __stage2\n",
            "    tmp = np.zeros((int(stage_status.tmph[k]), int(stage_status.tmpw[k]), 3))\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}